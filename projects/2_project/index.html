<!DOCTYPE html> <html lang="pt-br"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="cpZflIM2Qf3GHJJQgkqG_q0dw7v7eho0ixj41GaazsE"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Brazilian Sign Language Detection | Maurício de Aguiar Braz </title> <meta name="author" content="Maurício de Aguiar Braz"> <meta name="description" content="Using Deep Learning to recognize gestures in LIBRAS (Língua Brasileira de Sinais)."> <meta name="keywords" content="data science, github, git-hub, portfolio, statistics, software developer"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%88&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mauricioaguiar.github.io/projects/2_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Maurício</span> de Aguiar Braz </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Sobre </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projetos <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositórios </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Currículo </a> </li> <li class="nav-item "> <a class="nav-link" href="/certificates/">Certificados </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/news/">Novidades</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/publications/">Artigos e Referências</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Brazilian Sign Language Detection</h1> <p class="post-description">Using Deep Learning to recognize gestures in LIBRAS (Língua Brasileira de Sinais).</p> </header> <article> <section id="overview"> <h2>Project Overview</h2> <p>This project leverages deep learning techniques to detect and classify hand gestures used in Brazilian Sign Language (LIBRAS). The system processes video streams or images, identifies hand landmarks, and predicts the corresponding gesture using a trained neural network.</p> </section> <section id="methodology"> <h2>Methodology</h2> <ol> <li> <strong>Dependencies:</strong> The project uses libraries such as TensorFlow, MediaPipe, OpenCV, and scikit-learn for model training and gesture recognition.</li> <li> <strong>Data Preparation:</strong> A dataset of hand gestures is preprocessed and augmented to improve model robustness.</li> <li> <strong>Model Training:</strong> A neural network is trained to classify gestures based on extracted features from hand landmarks.</li> <li> <strong>Real-Time Detection:</strong> The system integrates with a webcam or video feed to perform real-time gesture recognition.</li> </ol> </section> <section id="landmark-detection"> <h2>Landmark Detection</h2> <p>Using MediaPipe and OpenCV, the system detects hand landmarks in real-time. These landmarks are essential for extracting features used in gesture classification.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/mediapipe-detection-480.webp 480w,/assets/img/signlanguagept-br/mediapipe-detection-800.webp 800w,/assets/img/signlanguagept-br/mediapipe-detection-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/mediapipe-detection.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Landmark Detection Example" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption">Example of detected hand landmarks using MediaPipe and OpenCV.</div> </section> <section id="gesture-capture"> <h2>Gesture Capture</h2> <p>Captured gestures are saved as input data for model training. Each gesture is labeled and stored in a structured format, ensuring consistency and accuracy during training.</p> </section> <section id="model-details"> <h2>Model Details</h2> <p>The model is built using a Sequential architecture, combining LSTM layers for temporal feature extraction and Dense layers for classification. The following configurations were used:</p> <ul> <li> <strong>Optimizer:</strong> Adam</li> <li> <strong>Loss Function:</strong> categorical_crossentropy</li> <li> <strong>Metrics:</strong> categorical_accuracy</li> </ul> <p>This architecture ensures effective learning of temporal dependencies in the gesture data.</p> <div class="row"> <div class="col-sm mt-6 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/summary-480.webp 480w,/assets/img/signlanguagept-br/summary-800.webp 800w,/assets/img/signlanguagept-br/summary-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/summary.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model Summary" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption">Model summary showing total parameters, trainable parameters, and non-trainable parameters.</div> <h3>Training Progress</h3> <p>The model was trained for 537 epochs, achieving convergence in both categorical accuracy and loss reduction:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/categorical_accuracy-480.webp 480w,/assets/img/signlanguagept-br/categorical_accuracy-800.webp 800w,/assets/img/signlanguagept-br/categorical_accuracy-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/categorical_accuracy.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Categorical Accuracy per Epoch" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Categorical accuracy over epochs.</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/loss_reduction-480.webp 480w,/assets/img/signlanguagept-br/loss_reduction-800.webp 800w,/assets/img/signlanguagept-br/loss_reduction-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/loss_reduction.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Loss Reduction per Epoch" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Loss reduction over epochs.</div> </div> </div> </section> <section id="results"> <h2>Results</h2> <p>The model successfully detects and classifies gestures with high accuracy. Below are examples of the detection pipeline for different gestures:</p> <div class="row"> <div class="col-sm-3 mt mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/detection_ola-oi-480.webp 480w,/assets/img/signlanguagept-br/detection_ola-oi-800.webp 800w,/assets/img/signlanguagept-br/detection_ola-oi-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/detection_ola-oi.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Gesture Detection: Oi/Olá" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Detection of the gesture "Oi/Olá".</div> </div> <div class="col-sm-3 mt mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/detection_obrigado-480.webp 480w,/assets/img/signlanguagept-br/detection_obrigado-800.webp 800w,/assets/img/signlanguagept-br/detection_obrigado-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/detection_obrigado.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Gesture Detection: Obrigado" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Detection of the gesture "Obrigado".</div> </div> <div class="col-sm-3 mt mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/detection_eu-te-amo-480.webp 480w,/assets/img/signlanguagept-br/detection_eu-te-amo-800.webp 800w,/assets/img/signlanguagept-br/detection_eu-te-amo-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/detection_eu-te-amo.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Gesture Detection: Eu te amo" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Detection of the gesture "Eu te amo".</div> </div> <div class="col-sm-3 mt mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/signlanguagept-br/detection_sem-input-480.webp 480w,/assets/img/signlanguagept-br/detection_sem-input-800.webp 800w,/assets/img/signlanguagept-br/detection_sem-input-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/signlanguagept-br/detection_sem-input.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Gesture Detection: Sem Input" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Detection when no gesture is input ("Sem Input").</div> </div> </div> <p>Further optimization is ongoing to improve detection speed and accuracy in real-world scenarios.</p> </section> <section id="future-work"> <h2>Future Work</h2> <ul> <li>Expand the dataset to include more gestures and variations.</li> <li>Integrate the system into a mobile or web application for broader accessibility.</li> <li>Improve robustness to handle complex backgrounds and lighting conditions.</li> </ul> </section> <footer> <p>For more details, visit the <a href="https://github.com/MauricioAguiar/SignLanguagePT-BR" rel="external nofollow noopener" target="_blank">GitHub repository</a> or check the repositories tab.</p> </footer> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Maurício de Aguiar Braz. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: February 25, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?bb11395757e9f109ef5e8877bae41636"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-FFT1J93D9K"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-FFT1J93D9K');
  </script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>